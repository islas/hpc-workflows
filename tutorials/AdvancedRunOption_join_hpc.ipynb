{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c69b9a1e-ee72-4e1a-9056-41ee55e505e3",
   "metadata": {},
   "source": [
    "# Utilizing advanced features - Joining <ins>tests</ins> for HPC submissions\n",
    "In this tutorial we will be exploring how to use advanced features of the framework. We will be using common terminology found in the repo's README.md - refer to that for any underlined terms that need clarification. Additionally, we will be building upon the material covered in the [Advanced Test Config - HPC argpacks](./AdvancedTestConfig_hpc_argpacks.ipynb); please review that tutorial if you haven't already. Anything in `\"code-quoted\"` format refers specifically to the test config, and anything in <ins>underlined</ins> format refers to specific terminology that can be found in the [README.md](../README.md).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68945657-ac3a-4b61-9712-83beb9ae26fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get notebook location\n",
    "shellReturn = !pwd\n",
    "notebookDirectory = shellReturn[0]\n",
    "print( \"Working from \" + notebookDirectory )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099ebede-a119-426f-8364-0e63385303ed",
   "metadata": {},
   "source": [
    "Advanced usage of the <ins>run script</ins> command line option `-j` will be the focus of this tutorial :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae03e835-c802-4afc-ac1e-f857578f107b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$notebookDirectory\"\n",
    "$1/../.ci/runner.py $1/../our-config.json -h | \\\n",
    "  tr $'\\n' '@' | \\\n",
    "  sed -e 's/[ ]\\+-h.*\\?entire suite from/.../g' | \\\n",
    "  sed -e 's/[ ]\\+-alt.*/.../g' | \\\n",
    "  tr '@' $'\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d99a85-afe9-4746-9bed-1ef4b6e2aae7",
   "metadata": {},
   "source": [
    "\n",
    "### Joining Tests for Single HPC Submission\n",
    "\n",
    "Tests can specify general resource usage and steps can further refine those requirements. This works well to individually submit each step independently to an HPC grid. However, for relatively small steps or if the smallest resource allocations are comparably large (e.g. whole node allocations for large core-count CPUs) one may want to aggregate the tests into larger workloads to be more effective with the resources. \n",
    "\n",
    "This can also be an appealing option if queue times on the grids are long, requiring individually submitted steps to each wait in the queue. Thus for steps with dependencies this would emulate re-entering the queue multiple times.\n",
    "\n",
    "To avoid the need to over-spec the test suite to one particular machine (remember we want this to remain generic and flexible) the framework natively supports joining tests and steps into single job submissions. Tests and steps should now be able to remain as small logically separate components, steering away from machine-specific large and fragile multiple tests in one script designs.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Check the FQDN of the node if using host-specific selections!</b>\n",
    "When using cummulative join features for HPC runs the host that actually runs the final individual step is actually the HPC node and not the login node from which the command was launched. Joining tests under one HPC job bundles all the specified tests and their respective steps into one HPC launch step that then runs the tests normally in the node. This can at times lead to different FQDN naming between where the initial launch of the job and where the step is finally run, depending on how your computing system had been configured.\n",
    "<br><br>\n",
    "    \n",
    "Final <ins>step argacks</ins> to the step only rely on the location where the step script is started (i.e. when \"Running command\" for that step is shown). This cah be affected by using the joining capabilities as the selected <ins>submit options</ins> may differ between where you launch and where it runs.\n",
    "\n",
    "The <ins>hpc argpacks</ins> required for the steps to be submitted to the grid, total aggregated via joining or submitted normally, will only ever rely on the host that starts the test suite (the HPC login node). They are never used in the node environment for the fully joined submission and thus are not affected by changes in FQDN.\n",
    "</div>\n",
    "\n",
    "#### Accumulate Resources\n",
    "Recall that each step in the end specifies its own individual set of `\"arguments\"` from its cummulative ancestry. The `\"resources\"` string field works the same way as all keys under `\"submit_options\"` do. The difference here is that `\"resoursces\"` is slightly more complex dictionary as opposed to a single dictionary of lists.\n",
    "\n",
    "As HPC systems can be very different in scheduler args, format, and resources available to request the simplest approach is to only carry the single string. Internally, when steps and tests are joined based on scheduler type the framework makes a best guess as to how resoursces should be combined and aggregated.\n",
    "\n",
    "The join option allows overriding specific \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee8f6a0-bc64-4111-8036-82541202a90b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
