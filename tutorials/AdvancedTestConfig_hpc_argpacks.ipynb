{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6d88dd1-eca6-404d-a013-62db28ba380a",
   "metadata": {},
   "source": [
    "# Utilizing advanced features - HPC <ins>argpacks</ins>\n",
    "In this tutorial we will be exploring how to use advanced features of the framework. We will be using common terminology found in the repo's README.md - refer to that for any underlined terms that need clarification. Additionally, we will be building upon the material covered in the [Advanced Test Config - Regex Argpacks](./AdvancedTestConfig_regex_argpacks.ipynb); please review that tutorial if you haven't already. Anything in `\"code-quoted\"` format refers specifically to the test config, and anything in <ins>underlined</ins> format refers to specific terminology that can be found in the [README.md](../README.md).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3addab4e-4ef2-450a-964c-974a56f97300",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get notebook location\n",
    "shellReturn = !pwd\n",
    "notebookDirectory = shellReturn[0]\n",
    "print( \"Working from \" + notebookDirectory )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a427930-e2ba-42e4-a375-1bd0244e7aee",
   "metadata": {},
   "source": [
    "Advanced usage of the json config option `\"hpc_arguments\"` under `\"submit_options\"` will be the focus of this tutorial :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d7b03a-7f99-422e-91d6-e2bf9e74296a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output template file documenting options\n",
    "from IPython.display import Markdown as md\n",
    "md( \"```jsonc\\n\" + open( notebookDirectory + \"/../.ci/template.json\", \"r\" )\n",
    "                        .read()\n",
    "                        .split( \"// specifics to each HPC system\" )[1]\n",
    "                        .split( \"// timelimit\" )[0] + \n",
    "   \"\\n```\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403a41d2-8c4f-4e5d-b8ee-be9cc3172499",
   "metadata": {},
   "source": [
    "\n",
    "## HPC Arguments as <ins>argpacks</ins>\n",
    "\n",
    "We should now be sufficiently familiar with <ins>argpacks</ins>, both regex and regular. For those looking to submit tests to an HPC grid, there is very often a desire to specify resources and generally the computing environment to check out for your use case. The testing framework facilitates this through the use of <ins>argpacks</ins>, with some slight caveats. While the core concepts remain the same, to differentiate them we will refer to \"normal\" argpacks as <ins>step argpacks</ins> and HPC ones as <ins>hpc argpacks</ins> (a third exists called <ins>resource argpacks</ins> but we'll get to that shortly)\n",
    "\n",
    "For our examples, as it would require an actual grid to demonstate we will be using the `-dry` option to simulate what would happen without actual execution as a dry-run. Due to the layout of the framework, this will result in command outputs that could be copy-pasted and executed in a valid hpc setup, so by inspecting those we can build confidence that this would work in a real system. \n",
    "\n",
    "To simplify later instructions, we will assume we are writing inputs for a PBS-style grid, however syntax changes for writing SLURM inputs is essentially the same and will be covered the following example. \n",
    "\n",
    "\n",
    "### Hello HPC World! Setting up HPC submissions\n",
    "\n",
    "Let's first construct a basic example that runs locally. Our \"Hello World!\" equivalent (same from the [Basic Test Config->Writing our own test config](./BasicTestConfig.ipynb#Writing-our-own-test-config))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3521dfb-e1d1-4308-84be-d7936ff02f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$notebookDirectory\"\n",
    "cat << EOF > $1/../our-config.json\n",
    "{\n",
    "  \"our-test\" : { \"steps\" : { \"our-step0\" : { \"command\" : \"./tests/scripts/echo_normal.sh\" } } }\n",
    "}\n",
    "EOF\n",
    "\n",
    "echo \"$( realpath $1/../our-config.json ) :\"\n",
    "cat $1/../our-config.json\n",
    "\n",
    "$1/../.ci/runner.py $1/../our-config.json -t our-test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fedc359-31aa-4eaa-9a2d-eff4f185c792",
   "metadata": {},
   "source": [
    "Great, no errors or if there are that's not great and try resolving them by restarting this notebook.\n",
    "\n",
    "We will use the `-fs` and `-i` options, and shortly add `-dry` as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4dfdb6-f6c2-4d3b-afee-a5d6914dd13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$notebookDirectory\"\n",
    "$1/../.ci/runner.py $1/../our-config.json -t our-test -fs -i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0fb5f7-d463-4e8b-ac60-1c2f331549c5",
   "metadata": {},
   "source": [
    "Now if we set the `\"submission\"` type to an HPC option (PBS) we should start to get some different output (using `-dry` to now account for potentially no HPC system available):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c388b935-fdfe-4f27-b5bd-534f5827a630",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$notebookDirectory\" \n",
    "cat << EOF > $1/../our-config.json\n",
    "{\n",
    "  \"submit_options\" :\n",
    "  {\n",
    "    \"submission\" : \"PBS\"\n",
    "  },\n",
    "  \"our-test\" : { \"steps\" : { \"our-step0\" : { \"command\" : \"./tests/scripts/echo_normal.sh\" } } }\n",
    "}\n",
    "EOF\n",
    "\n",
    "echo \"$( realpath $1/../our-config.json ) :\"\n",
    "cat $1/../our-config.json\n",
    "\n",
    "$1/../.ci/runner.py $1/../our-config.json -t our-test -fs -i -dry\n",
    "\n",
    "# this is just to suppress bash magic failing error clutter\n",
    "echo \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0c0993-1eff-4d85-a893-19b07de0a862",
   "metadata": {},
   "source": [
    "Our run should have failed with some helpful output that we have not given an account to use for our submission. As accounts are what are used to bill to grid allocations and sometimes they are kept private within an organization this is not put into the test config. Instead we will provide it via command-line options using `--account/-a`. Let's say our account is \"WORKFLOWS\" : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1b41aa-4dd9-49cd-8cba-0611d07746cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$notebookDirectory\" \n",
    "cat << EOF > $1/../our-config.json\n",
    "{\n",
    "  \"submit_options\" :\n",
    "  {\n",
    "    \"submission\" : \"PBS\"\n",
    "  },\n",
    "  \"our-test\" : { \"steps\" : { \"our-step0\" : { \"command\" : \"./tests/scripts/echo_normal.sh\" } } }\n",
    "}\n",
    "EOF\n",
    "\n",
    "echo \"$( realpath $1/../our-config.json ) :\"\n",
    "cat $1/../our-config.json\n",
    "\n",
    "$1/../.ci/runner.py $1/../our-config.json -t our-test -fs -i -dry -a WORKFLOWS\n",
    "\n",
    "# this is just to suppress bash magic failing error clutter\n",
    "echo \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7debd629-82dd-4540-bb19-f5843f3d727a",
   "metadata": {},
   "source": [
    "We have another error : we need to provide a queue to submit to. We should also set a timelimit, though not required. When using HPC submissions `\"queue\"` becomes a required field that must be defined by the time the step to run is resolved. Let's say our queue is economy and our timelimit is 1 minute.\n",
    "\n",
    "The information we have so far is most likely not enough to make a full HPC job submission, but for now let's assume that we don't need anything else to at least get things running.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc50a57-7aa7-4793-bbea-1c391c0881ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$notebookDirectory\" \n",
    "cat << EOF > $1/../our-config.json\n",
    "{\n",
    "  \"submit_options\" :\n",
    "  {\n",
    "    \"submission\" : \"PBS\",\n",
    "    \"queue\"      : \"economy\",\n",
    "    \"timelimit\"  : \"00:01:00\"\n",
    "  },\n",
    "  \"our-test\" : { \"steps\" : { \"our-step0\" : { \"command\" : \"./tests/scripts/echo_normal.sh\" } } }\n",
    "}\n",
    "EOF\n",
    "\n",
    "echo \"$( realpath $1/../our-config.json ) :\"\n",
    "cat $1/../our-config.json\n",
    "\n",
    "$1/../.ci/runner.py $1/../our-config.json -t our-test -fs -i -dry -a WORKFLOWS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4d0f73-a9c4-41c2-bbea-99f6c8243ef0",
   "metadata": {},
   "source": [
    "Two things should stand out as different when looking at the output :\n",
    "* first is that our dry-run option has made the text where our inline output would have been into a statement that it is a dry-run\n",
    "* second is that our step command _looks_ like it became way more complicated.\n",
    "\n",
    "The command that would run is now [for PBS] `qsub` to submit our HPC job. What follows is the translation of information either determined internally or given by us via config or command line option into that command's most standard flags. Breaking it down we see :\n",
    "* from our config\n",
    "  * `-q economy`\n",
    "  * `-l walltime=00:01:00`\n",
    "* from command line\n",
    "  * `-A WORKFLOWS`\n",
    "* internally determined from ancestry to set the job name and output file location\n",
    "  * `-N our-config.our-test.our-step0`\n",
    "  * `-j oe -o /home/aislas/hpc-workflows/our-config.our-test.our-step0.log`\n",
    "\n",
    "### Simple <ins>hpc argpacks</ins> structure\n",
    "\n",
    "The framework has no idea what else needs to be required or what flags are necessary, so `\"hpc_arguments\"` as <ins>argpacks</ins> handles generalized input. It is on YOU the user to fill in the rest of what would be required to submit your job.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Recall:</b>\n",
    "The <code>\"submit_options\"</code> block is hierarchally inherited as they get closer to steps so for global options we need only define them once at the top level to be sufficient\n",
    "</div>\n",
    " \n",
    "We should now start to fill in the resource requests. First we will want at least one node. As noted in the [.ci/template.json](../.ci/template.json) we will first need to make an <ins>hpc argpack</ins> with the flag we want as the first key. Note that unlike <ins>step argpacks</ins>, the value of <ins>hpc argpacks</ins> will be a `{}` dictionary of one key pointing to another nested dictionary instead of `[]` for a list of arguments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f00145-4555-4d63-9ee4-f7962dbc62ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output template file documenting options\n",
    "from IPython.display import Markdown as md\n",
    "md( \"```jsonc\\n\" + open( notebookDirectory + \"/../.ci/template.json\", \"r\" )\n",
    "                        .read()\n",
    "                        .split( \"// specifics to each HPC system\" )[1]\n",
    "                        .split( \"        {\" )[0] + \n",
    "   \"\\n```\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de27b833-e57b-4206-afbd-a9ec3d5d666a",
   "metadata": {},
   "source": [
    "Let's focus first on just forming the <ins>hpc argpack</ins> and getting our flag to appear, worrying about entries into the sub-dictionary later. We'll name our argpack \"node_select\" : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3527f1-fdfc-4beb-9ed5-ce7f2bab13a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$notebookDirectory\" \n",
    "cat << EOF > $1/../our-config.json\n",
    "{\n",
    "  \"submit_options\" :\n",
    "  {\n",
    "    \"submission\" : \"PBS\",\n",
    "    \"queue\"      : \"economy\",\n",
    "    \"timelimit\"  : \"00:01:00\",\n",
    "    \"hpc_arguments\" :\n",
    "    {\n",
    "      \"node_select\" : { \"-l\" : {} }\n",
    "    }\n",
    "  },\n",
    "  \"our-test\" : { \"steps\" : { \"our-step0\" : { \"command\" : \"./tests/scripts/echo_normal.sh\" } } }\n",
    "}\n",
    "EOF\n",
    "\n",
    "echo \"$( realpath $1/../our-config.json ) :\"\n",
    "cat $1/../our-config.json\n",
    "\n",
    "$1/../.ci/runner.py $1/../our-config.json -t our-test -fs -i -dry -a WORKFLOWS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4aea3c1-fcb3-4ff3-939b-e7e9a39da34b",
   "metadata": {},
   "source": [
    "We should now see that there is an additional `-l` option to `qsub` before all the automatic hpc arguments. Also, if we look closely at the supplemental output between `Submitting step our-step0...` and `Running command:` we see _all_ <ins>argpack</ins> gathering. So now there is info under `Gathering HPC argument packs...` detailing the addition of our \"node_select\" entry and the option `-l` being added. The final generated output is listed as well for debug purposes on more complex entries.\n",
    "\n",
    "### Using <ins>resource argpacks</ins>\n",
    "\n",
    "Now to add our node count selection. To do this we will write a <ins>resource argpack</ins> inside the dictionary of our `\"<option>\"` (in this case `\"-l\"`). These <ins>argpacks</ins> take only one value (int or string) vs the list of <ins>step argpacks</ins> or the dictionary of <ins>hpc argpacks</ins>. Our resource will be \"select\" and we will request one node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da986996-a23e-45e4-9ec7-a120665cded5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$notebookDirectory\" \n",
    "cat << EOF > $1/../our-config.json\n",
    "{\n",
    "  \"submit_options\" :\n",
    "  {\n",
    "    \"submission\" : \"PBS\",\n",
    "    \"queue\"      : \"economy\",\n",
    "    \"timelimit\"  : \"00:01:00\",\n",
    "    \"hpc_arguments\" :\n",
    "    {\n",
    "      \"select\" : { \"-l\" : { \"select\" : 1 } }\n",
    "    }\n",
    "  },\n",
    "  \"our-test\" : { \"steps\" : { \"our-step0\" : { \"command\" : \"./tests/scripts/echo_normal.sh\" } } }\n",
    "}\n",
    "EOF\n",
    "\n",
    "echo \"$( realpath $1/../our-config.json ) :\"\n",
    "cat $1/../our-config.json\n",
    "\n",
    "$1/../.ci/runner.py $1/../our-config.json -t our-test -fs -i -dry -a WORKFLOWS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb71de76-62a5-4443-8ef5-d614276f17a7",
   "metadata": {},
   "source": [
    "The output under `Gathering HPC argument packs...` now has an additional line indented under `Adding option -l`. Much like the <ins>step argpacks</ins>, a `From <origin> ...` prefix is added to the details of the <ins>resource argpack</ins>. Actually, our <ins>hpc argpack</ins> also has this, but it is listed as `[<origins>]` (plural) as the nested nature can lead to multiple contributors to the final result.\n",
    "\n",
    "Our \"select\" resource was added using the syntax for PBS noted in the .ci/template.json of `=` to join the resource name `\"select\"` ant value `1` in the config together. One problem though - our resultant argument to `qsub` is `-lselect=1`! This isn't correct syntax at all...\n",
    "\n",
    "Referring back to the .ci/template.json, a particular line to focus on now is :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7810a4a-61a4-4e44-82a2-7218267b7548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output template file documenting options\n",
    "from IPython.display import Markdown as md\n",
    "md( \"```jsonc\\n\" + open( notebookDirectory + \"/../.ci/template.json\", \"r\" )\n",
    "                        .read()\n",
    "                        .split( \"with respect to this <argpack>\" )[1]\n",
    "                        .split( \"//   non-empty\" )[0] + \n",
    "   \"\\n```\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b1e878-687f-4f31-9e2a-d72213409201",
   "metadata": {},
   "source": [
    "There is no additional formatting in the concatenation of our <ins>resource argpacks</ins> and the `\"<option>\"` we specified. Looking back at our `\"-l\"` entry, there is no space to separate resource arguments and the flag. Let's change that :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6bbe66f-ebfa-4ace-86cd-925c2624a83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$notebookDirectory\" \n",
    "cat << EOF > $1/../our-config.json\n",
    "{\n",
    "  \"submit_options\" :\n",
    "  {\n",
    "    \"submission\" : \"PBS\",\n",
    "    \"queue\"      : \"economy\",\n",
    "    \"timelimit\"  : \"00:01:00\",\n",
    "    \"hpc_arguments\" :\n",
    "    {\n",
    "      \"select\" : { \"-l \" : { \"select\" : 1 } }\n",
    "    }\n",
    "  },\n",
    "  \"our-test\" : { \"steps\" : { \"our-step0\" : { \"command\" : \"./tests/scripts/echo_normal.sh\" } } }\n",
    "}\n",
    "EOF\n",
    "\n",
    "echo \"$( realpath $1/../our-config.json ) :\"\n",
    "cat $1/../our-config.json\n",
    "\n",
    "$1/../.ci/runner.py $1/../our-config.json -t our-test -fs -i -dry -a WORKFLOWS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4568ce-0a12-4c60-974e-54590038303a",
   "metadata": {},
   "source": [
    "That looks like a fully successful `qsub` command now! The same concept could be applied to SLURM, where an `\"<option>\"` like \"--gres=\" uses no spaces to appropriately concatenate the listed resources.\n",
    "\n",
    "\n",
    "#### Regex-based HPC <ins>argpacks</ins>\n",
    "\n",
    "While there are some differences in the value syntax and final constucted output between the <ins>argpack</ins> variants, the ability hierarchically pass down, override, and filter via regexes and <ins>ancestry</ins> remains more or less the same. These core features are why they are all named <ins>argpacks</ins>.\n",
    "<br><br>\n",
    "##### Limitations on <ins>resource argpacks</ins>\n",
    "The <ins>resource argpacks</ins> allow for `\"<regex>::<argpack>\"` syntax with the caveat that the \"basename\" `\"<argpack>\"` MUST be unique. This special limitation is in place because `\"<argpack>\"` is always used as the resource name, regex or not. Thus to  avoid resource duplications if two or more <ins>resource argpacks</ins> appear with the same \"basename\" (one at least being regex-based) within the same <ins>hpc argpack</ins> the suite will throw an error. \n",
    "\n",
    "While this seems limiting at first, the safety to only select unique resources within an <ins>hpc argpack</ins> is crucial to a higher success rate of submitted jobs when dealing with regexes and variably applicable arguments. Additionally, multiple regex-<ins>resource argpacks</ins> may still exist with smart management of <ins>hpc argpacks</ins> as wrappers. \n",
    "<br><br>\n",
    "##### Limitations on <ins>hpc argpacks</ins>\n",
    "The <ins>hpc argpacks</ins> allow for `\"<regex>::<argpack>\"` syntax with a caveat similar to that of <ins>resource argpacks'</ins> uniqueness requirements. The <ins>hpc argpacks</ins> must be unique for a particular step. This means that for any specific step after its host-specific `\"submit_options\"` have been selected, and all <ins>argpacks</ins> of all varieties have been resolved for it based on inheritance, overriding, and <ins>ancestry</ins> that matches regexes uniqueness must be preserved, but beforehand duplicates may exist. Thus, multiple <ins>hpc argpacks</ins> with the same \"basename\" can exist in the config, but at the step level no duplicates can be selected.\n",
    "\n",
    "These rules are in principle simple, but can admittedly seem complex at first so let's walk through a few examples. To start let's show the simpler uniqueness requirements of <ins>resource argpacks</ins> :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ad7722-d251-44ab-bbc7-360ccccc41a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$notebookDirectory\" \n",
    "cat << EOF > $1/../our-config.json\n",
    "{\n",
    "  \"submit_options\" :\n",
    "  {\n",
    "    \"submission\" : \"PBS\",\n",
    "    \"queue\"      : \"economy\",\n",
    "    \"timelimit\"  : \"00:01:00\",\n",
    "    \"hpc_arguments\" :\n",
    "    {\n",
    "      \"select\" : { \"-l \" : { \".*less-nodes.*::select\" : 1 } }\n",
    "    }\n",
    "  },\n",
    "  \"our-test\" :\n",
    "  {\n",
    "    \"submit_options\" :\n",
    "    {\n",
    "      \"hpc_arguments\" : \n",
    "      {\n",
    "        \"select\" : { \"-l \" : { \".*more-nodes.*::select\" : 2 } }\n",
    "      }\n",
    "    },\n",
    "    \"steps\" : { \"our-step0-less-nodes\" : { \"command\" : \"./tests/scripts/echo_normal.sh\" } }\n",
    "  }\n",
    "}\n",
    "EOF\n",
    "\n",
    "echo \"$( realpath $1/../our-config.json ) :\"\n",
    "cat $1/../our-config.json\n",
    "\n",
    "$1/../.ci/runner.py $1/../our-config.json -t our-test -fs -i -dry -a WORKFLOWS\n",
    "echo \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96bb1862-b229-400d-981f-c3b20a3d7d31",
   "metadata": {},
   "source": [
    "We should see that the run failed at the test level. When `\"our-test\"` was being instantiated it inherited the top-level `\"hpc_arguments\"`, causing the conflict since both <ins>resource argpacks</ins> listed use the same \"basename\" 'select'.\n",
    "\n",
    "To have our step be able to select less nodes based on its name, we should use an <ins>hpc argpack</ins> as a wrapper instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7fa1ce-b730-4ea7-b60e-58e8b2ce3be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$notebookDirectory\" \n",
    "cat << EOF > $1/../our-config.json\n",
    "{\n",
    "  \"submit_options\" :\n",
    "  {\n",
    "    \"submission\" : \"PBS\",\n",
    "    \"queue\"      : \"economy\",\n",
    "    \"timelimit\"  : \"00:01:00\",\n",
    "    \"hpc_arguments\" :\n",
    "    {\n",
    "      \".*less-nodes.*::select\" : { \"-l \" : { \"select\" : 1 } }\n",
    "    }\n",
    "  },\n",
    "  \"our-test\" :\n",
    "  {\n",
    "    \"submit_options\" :\n",
    "    {\n",
    "      \"hpc_arguments\" : \n",
    "      {\n",
    "        \".*more-nodes.*::select\" : { \"-l \" : { \"select\" : 2 } }\n",
    "      }\n",
    "    },\n",
    "    \"steps\" : { \"our-step0-less-nodes\" : { \"command\" : \"./tests/scripts/echo_normal.sh\" } }\n",
    "  }\n",
    "}\n",
    "EOF\n",
    "\n",
    "echo \"$( realpath $1/../our-config.json ) :\"\n",
    "cat $1/../our-config.json\n",
    "\n",
    "$1/../.ci/runner.py $1/../our-config.json -t our-test -fs -i -dry -a WORKFLOWS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae834ec-2fbe-4bae-9dcd-21e88cdf363c",
   "metadata": {},
   "source": [
    "From the above config, we see that the <ins>hpc argpack</ins> 'select' is technically duplicated as `\".*more-nodes.*::select\"` and `\".*less-nodes.*::select\"`. Note however that at the time the step is determining what to run only one is used. To show that two cannot exist at this point we can make either the regexes match verbatim or at least match the final step <ins>ancestry</ins>. Let's do the latter : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2631a8a-6995-41fc-aa2c-c590349b087c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$notebookDirectory\" \n",
    "cat << EOF > $1/../our-config.json\n",
    "{\n",
    "  \"submit_options\" :\n",
    "  {\n",
    "    \"submission\" : \"PBS\",\n",
    "    \"queue\"      : \"economy\",\n",
    "    \"timelimit\"  : \"00:01:00\",\n",
    "    \"hpc_arguments\" :\n",
    "    {\n",
    "      \".*less-nodes.*::select\" : { \"-l \" : { \"select\" : 1 } }\n",
    "    }\n",
    "  },\n",
    "  \"our-test\" :\n",
    "  {\n",
    "    \"submit_options\" :\n",
    "    {\n",
    "      \"hpc_arguments\" : \n",
    "      {\n",
    "        \".*our.*::select\" : { \"-l \" : { \"select\" : 2 } }\n",
    "      }\n",
    "    },\n",
    "    \"steps\" : { \"our-step0-less-nodes\" : { \"command\" : \"./tests/scripts/echo_normal.sh\" } }\n",
    "  }\n",
    "}\n",
    "EOF\n",
    "\n",
    "echo \"$( realpath $1/../our-config.json ) :\"\n",
    "cat $1/../our-config.json\n",
    "\n",
    "$1/../.ci/runner.py $1/../our-config.json -t our-test -fs -i -dry -a WORKFLOWS\n",
    "echo \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24aa06a6-64d9-49d6-9dad-1563760ae1d4",
   "metadata": {},
   "source": [
    "Now our config is failing to load since if `our-step0-less-nodes` were to have run it would have selected both <ins>hpc argpacks</ins>. Before running any of the steps to prevent wasted time of potentially failing in the middle of a test due to framework-imposed rules all aspects are validated first. This ensures that to the best of the framework's knowledge your submitted steps should be acceptable by the scheduler.\n",
    "\n",
    "The above example also shows why duplicates for <ins>hpc argpacks</ins> are allowed generically before being restricted at the step level. It allows us to make \"wrappers\" as shown in the `\"hpc_arguments\" : { \".*more-nodes.*::select\" ...` example to effectively override resources with regexes whilst adhering to the <ins>resource argpacks</ins> rules.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
