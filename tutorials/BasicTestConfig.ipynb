{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ed12d27",
   "metadata": {},
   "source": [
    "# Creating a basic test config\n",
    "The definition of all tests from a respective test config as seen in the tests/ examples. In this tutorial we will be breaking down how to write a simple but fully working test config in the expected JSON format. We will be using common terminology found in the repo's README.md - refer to that for any underlined terms that need clarification. Anything in `\"code-quoted\"` format refers specifically to the test config.\n",
    "\n",
    "## Test Config Format\n",
    "So what is the <ins>test config</ins> format, aside from JSON? It will look like this :\n",
    "```jsonc\n",
    "{\n",
    "  // this is the only KEYWORD at this level\n",
    "  // ALL ENTRIES ARE OPTIONAL UNLESS NOTED\n",
    "  \"submit_options\" : // These are globally applied submit options\n",
    "  {\n",
    "    // KEYWORDS\n",
    "   \n",
    "    // can be relative or absolute, applied from root directory\n",
    "    \"working_directory\" : \"path\",\n",
    "   \n",
    "    // generally needed for any HPC system\n",
    "    \"queue\"             : \"HPC queue\",\n",
    "   \n",
    "    // specific to each HPC system\n",
    "    \"resources\"         : \"HPC resources flags and options\",\n",
    "   \n",
    "    // timelimit for a step to complete\n",
    "    \"timelimit\"         : \"HH:MM:SS\",\n",
    "   \n",
    "    // uses HPC wait/blocking feature - generally not recommended\n",
    "    \"wait\"              : \"true if set\",\n",
    "   \n",
    "    // use one of the options to specify how steps should run\n",
    "    \"submission\"        : \"LOCAL\", // PBS|SLURM|LOCAL\n",
    "   \n",
    "    // dict of argpacks\n",
    "    \"arguments\"         :\n",
    "    {\n",
    "      // argpacks can be any valid string but all must be unique\n",
    "      // Recommended to not contain spaces or periods, character pattern\n",
    "      // '::' is reserved for regex-based argpacks\n",
    "     \n",
    "      // list of arguments to this specific <argpack>\n",
    "      // They DO NOT undergo shell-expansion, so $ENV_VAR will be verbatim passed in\n",
    "      \"<argpack>\"          : [ \"list\", \"of\", \"arguments\" ],\n",
    "     \n",
    "      // <regex> should be a valid regex usable by python's re module\n",
    "      // <argpack> can match the above <argpack> string since the full\n",
    "      // strings are unique, but they will be considered separate and\n",
    "      // future definitions will only override the specific unique match\n",
    "      // Single arguments with spaces should be entered as one string\n",
    "      \"<regex>::<argpack>\" : [ \"-f\", \"one whole arg\", \"-x\" ]\n",
    "    },\n",
    "    // NO MORE KEYWORDS AT THIS LEVEL, ANYTHING ELSE IS CONSIDERED A HOST-SPECIFIC SUBSET\n",
    "    // subset will be applied if key is found inside host FQDN\n",
    "    // NOT REGEX - this is just python `if key in fqdn`\n",
    "    \"match-fqdn\" :      \n",
    "    {\n",
    "      // Any of the \"submit_options\" KEYWORDS - host-specific subsets cannot be nested\n",
    "      // When steps are resolved if a host-specific subset matches it will be applied\n",
    "      // AFTER all generic submit_options have been applied\n",
    "    },\n",
    "    // No limit on number of host-specific subsets as long as they are unique\n",
    "    \"may-match-other-host\" :\n",
    "    {\n",
    "    }\n",
    "  },\n",
    " \n",
    "  // everything that isn't \"submit_options\" is considered a test name\n",
    "  // Like argpacks, they can be named anything unique amongst tests, but\n",
    "  // avoid using spaces and periods. Recommended characters are [a-zA-Z_-+]\n",
    "  \"test-name\" :\n",
    "  {\n",
    "    \"submit_options\" : {}, // EXACT SAME RULES AS ABOVE APPLY\n",
    "    // Additional KEYWORD\n",
    "    // A dict of steps, order of entry does not determine order of execution\n",
    "    \"steps\" : // REQUIRED KEYWORD\n",
    "    {\n",
    "      // NO KEYWORDS AT THIS LEVEL, EVERYTHING IS CONSIDERED A STEP\n",
    "      // Same naming rules as tests apply\n",
    "      \"step-A\" :\n",
    "      {\n",
    "        \"submit_options\" : {}, // EXACT SAME RULES AS ABOVE APPLY (see the pattern?)\n",
    "        // ADDITIONAL KEYWORDS\n",
    "         \n",
    "        // REQUIRED KEYWORD\n",
    "        // Script to run, not limited to `sh`. Executed from root or working_directory if specified\n",
    "        \"command\"        : \"filepath/to/script/to/run/from_root_or_workingDir.sh\",\n",
    "        \n",
    "        // Similar layout to argpack argument listing, but this is not an argpack\n",
    "        // this list is ALWAYS FIRST before any and all argpacks\n",
    "        \"arguments\"      : [ \"also\", \"a list of arguments\" ],\n",
    "        \n",
    "        // Specify and determine the inter-dependency order of steps\n",
    "        // NO CIRCULAR OR DEADLOCK PROTECTION LOGIC EXISTS SO BE CAREFUL TO SET THIS CORRECTLY\n",
    "        \"dependencies\" :\n",
    "        {\n",
    "          // dict of step names verbatim and dependency mapping using \n",
    "          // generally standard HPC-dependency nomenclature\n",
    "          // \n",
    "          \"step-B\" : \"afterany\" // after|afterok|afternotok|afterany\n",
    "        }\n",
    "      },\n",
    "      \"step-B\" :\n",
    "      {\n",
    "        // submit_options, arguments, and dependecies  are OPTIONAL KEYWORDS\n",
    "        \"command\" : \"other/command.py\"\n",
    "      }\n",
    "    }\n",
    "  },\n",
    "  \"other-test\" :\n",
    "  {\n",
    "    // submit_options is OPTIONAL KEYWORD\n",
    "    \"steps\" :\n",
    "    {\n",
    "      // step names only need to be unique within their respective test's \"steps\" section\n",
    "      \"step-A\" : { \"command\" : \"foobar.csh\" }\n",
    "    }\n",
    "  }\n",
    "  // ...and so on...\n",
    "  // ALL KEYWORDS ARE OPTIONAL **EXCEPT** :\n",
    "  //   [under a test]\n",
    "  //     - steps\n",
    "  //   [under a step]\n",
    "  //     - command\n",
    "}\n",
    "```\n",
    "\n",
    "The bulk of the the configurable power of this layout is generally carried by the `\"submit_options\"` and its ability to be inherited + overridden, especially on a per-host-FQDN manner. \n",
    "\n",
    "\n",
    "## Writing our own test config\n",
    "The explanation of the file layout is useful for knowing all available options in the test config, but what if you want to just get started or maybe don't even need all the features? What is the simplest way to start? Let's begind with the most barebones config of :\n",
    "```json\n",
    "{\n",
    "  \"our-test\" : { \"steps\" : { \"our-step0\" : { \"command\" : \"./tests/scripts/echo_normal.sh\" } } }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914a55e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get notebook location\n",
    "shellReturn = !pwd\n",
    "notebookDirectory = shellReturn[0]\n",
    "print( \"Working from \" + notebookDirectory )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da27445",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$notebookDirectory\"\n",
    "cat << EOF > $1/../our-config.json\n",
    "{\n",
    "  \"our-test\" : { \"steps\" : { \"our-step0\" : { \"command\" : \"./tests/scripts/echo_normal.sh\" } } }\n",
    "}\n",
    "EOF\n",
    "\n",
    "echo \"$( realpath $1/../our-config.json ) :\"\n",
    "cat $1/../our-config.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2276540e",
   "metadata": {},
   "source": [
    "Now that we have that test config ready, let's run it to make sure it works with our <ins>run script</ins>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e213502",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$notebookDirectory\"\n",
    "$1/../.ci/runner.py $1/../our-config.json -t our-test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23356d60",
   "metadata": {},
   "source": [
    "Excellent! While we won't go into the more complex launch options, we can make the <ins>test</ins> run as if already inside the process pool to see even clearer what would happen in the `_stdout.log` redirect using the `--forceSingle/-fc` option. We could look at the log as well but this way mimics what would happen, and gives you a better idea that nothing truly complex is happening under the hood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ae5809",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$notebookDirectory\"\n",
    "$1/../.ci/runner.py $1/../our-config.json -t our-test --forceSingle # we could shorten this option to -fc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245494ee",
   "metadata": {},
   "source": [
    "One step further is to inline the <ins>step</ins> output. Again, we will not do a deep-dive of launch options here, but instead are building up to a method of running an example <ins>suite of tests</ins> that doesn't rely on opening logfiles. This is mainly to better suit the notebook format. To inline our step we can add `-inlineLocal/-i` to our run script options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7204c7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$notebookDirectory\"\n",
    "$1/../.ci/runner.py $1/../our-config.json -t our-test -fc -i # using shorthand options"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a6af17",
   "metadata": {},
   "source": [
    "## Adding step arguments\n",
    "Okay, now that we have that printing neatly we can see that our example script doesn't do a whole lot aside from echoing our success <ins>keyphrase</ins> `TEST echo_normal.sh PASS`. Not much of a test?\n",
    "\n",
    "Let's add some <ins>arguments</ins> and observe how they get routed to the step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06c385f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$notebookDirectory\"\n",
    "cat << EOF > $1/../our-config.json\n",
    "{\n",
    "  \"our-test\" : \n",
    "  { \n",
    "    \"steps\" : \n",
    "    { \n",
    "      \"our-step0\" : \n",
    "      { \n",
    "        \"command\" : \"./tests/scripts/echo_normal.sh\",\n",
    "        \"arguments\" : [ \"foobar\" ]\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "EOF\n",
    "\n",
    "echo \"$( realpath $1/../our-config.json ) :\"\n",
    "cat $1/../our-config.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06fa9911",
   "metadata": {},
   "source": [
    "Now we run again, but this time note the changes in both the step command listed after the line starting with `[step::our-step0]...Running command` and the actual step output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcfaa63",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$notebookDirectory\"\n",
    "$1/../.ci/runner.py $1/../our-config.json -t our-test -fc -i # using shorthand options"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e200f4",
   "metadata": {},
   "source": [
    "## Step dependencies\n",
    "Let's go ahead and add another step, but with this one having a <ins>dependency</ins> on the first causing it to run only after the first has completed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b51dd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$notebookDirectory\"\n",
    "cat << EOF > $1/../our-config.json\n",
    "{\n",
    "  \"our-test\" : \n",
    "  { \n",
    "    \"steps\" : \n",
    "    { \n",
    "      \"our-step0\" : \n",
    "      { \n",
    "        \"command\" : \"./tests/scripts/echo_normal.sh\",\n",
    "        \"arguments\" : [ \"foobar\" ]\n",
    "      },\n",
    "      \"our-step1\" : \n",
    "      { \n",
    "        \"command\" : \"./tests/scripts/echo_normal.sh\",\n",
    "        \"arguments\" : [ \"why\", \"not more\", \"args?\" ],\n",
    "        \"dependencies\" : { \"our-step0\" : \"afterany\" }\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "EOF\n",
    "\n",
    "echo \"$( realpath $1/../our-config.json ) :\"\n",
    "cat $1/../our-config.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4feb70af",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$notebookDirectory\"\n",
    "$1/../.ci/runner.py $1/../our-config.json -t our-test -fc -i # using shorthand options"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7865341f",
   "metadata": {},
   "source": [
    "Most of the output should look very similar, but notice that after running `our-step0` there is an additional line now stating `Notifying children...` just before `our-step1` begins to run. This tells us that we have properly tied a dependency between `our-step0` as a parent step and `our-step1` as a dependent child step.\n",
    "\n",
    "Going a little further, if we look at `our-step1`'s respective `Running command` line we see that `\"not more\"` is being passed in as one whole argument. This emulates exactly how it was listed in the `\"arguments\"` for the step.\n",
    "\n",
    "## Adding argpacks\n",
    "Imagine we now want to add some additional generalized arguments to both our steps. We have the ability to add these higher-defined arguments as <ins>argpacks</ins> from any level of `\"submit_options\"` that appears in a step's <ins>ancestry</ins>. For the sake of demonstrating this, we will not add an <ins>argpack</ins> at the highest level, and instead show how it can be inherited from the <ins>test</ins> level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1038d115",
   "metadata": {},
   "outputs": [],
   "source": [
    " %%bash -s \"$notebookDirectory\"\n",
    "cat << EOF > $1/../our-config.json\n",
    "{\n",
    "  \"our-test\" : \n",
    "  { \n",
    "    \"submit_options\" :\n",
    "    {\n",
    "      \"arguments\" :\n",
    "      {\n",
    "        \"our-default-argpack\" : [ \"foobar\" ]\n",
    "      }\n",
    "    },\n",
    "    \"steps\" : \n",
    "    { \n",
    "      \"our-step0\" : \n",
    "      { \n",
    "        \"command\" : \"./tests/scripts/echo_normal.sh\",\n",
    "        \"arguments\" : [ \"foobar\" ]\n",
    "      },\n",
    "      \"our-step1\" : \n",
    "      { \n",
    "        \"command\" : \"./tests/scripts/echo_normal.sh\",\n",
    "        \"arguments\" : [ \"why\", \"not more\", \"args?\" ],\n",
    "        \"dependencies\" : { \"our-step0\" : \"afterany\" }\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "EOF\n",
    "\n",
    "echo \"$( realpath $1/../our-config.json ) :\"\n",
    "cat $1/../our-config.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915d0957",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$notebookDirectory\"\n",
    "$1/../.ci/runner.py $1/../our-config.json -t our-test -fc -i # using shorthand options\n",
    "\n",
    "# Clean up all generated logs and files\n",
    "rm $1/../our-config.json $1/../*.log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8903a5",
   "metadata": {},
   "source": [
    "Now notice how in the step preparation phase between `Submitting step ...` and `Running command` for each respective step we now have a new output of `From our-test adding argument pack 'our-default-argpack'...`. This line tells us both the origin of the <ins>argpack</ins> (which level in our step's <ins>ancestry</ins> provided the defintion) and the effective values of the arguments to be added. Any additional lines of the format `From <origin> adding argument pack '<argpack>'...` would also be listed in the order applied to the step's run command, where `<argpack>` is determining that order.\n",
    "\n",
    "This <ins>argpack</ins> is always listed after our steps' <ins>arguments</ins> in the step's final command listed - this is important to note!\n",
    "\n",
    "This concludes our simplest example of a test config that gives enough of an overview to provide users with enough understanding to put together a sufficiently capabale test <ins>suite</ins>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
